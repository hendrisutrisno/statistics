

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4. Covariance &mdash; Statistics</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Correlation" href="stat2_05.html" />
    <link rel="prev" title="3. Independence of Random Variables" href="stat2_03.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Courses</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../statistics1/index.html">Statistics 1</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Statistics 2</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="stat2_01.html">1. Joint probability for discrete variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_02.html">2. Marginal Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_03.html">3. Independence of Random Variables</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4. Covariance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-outcomes">Learning Outcomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#purpose-and-use-cases">Purpose and Use Cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-concept-and-notation">Core Concept and Notation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#random-variables">Random variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#means-expected-values">Means (expected values)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deviations-from-the-mean">Deviations from the mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="#expected-value-of-a-function-of-two-variables">Expected value of a function of two variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#definition-of-covariance">Definition of Covariance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-the-multiplication-works">Why the multiplication works</a></li>
<li class="toctree-l4"><a class="reference internal" href="#a-convenient-formula">A convenient formula</a></li>
<li class="toctree-l4"><a class="reference internal" href="#interpretation-of-the-sign">Interpretation of the sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="#connection-to-independence">Connection to independence</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#worked-example">Worked Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#scenario">Scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-1-find-the-marginal-distributions">Step 1: Find the marginal distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-2-compute-the-means-mu-x-and-mu-y">Step 2: Compute the means mu_X and mu_Y</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-3-compute-e-xy-using-the-joint-distribution">Step 3: Compute E[XY] using the joint distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-4-compute-covariance">Step 4: Compute covariance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-5-interpret-the-result">Step 5: Interpret the result</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#visual-intuition">Visual Intuition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#a-simple-point-cloud-picture">A simple point-cloud picture</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-above-below-average-picture">The “above/below average” picture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#discussion-and-common-errors">Discussion and Common Errors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#zero-covariance-and-independence">Zero covariance and independence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#e-xy-versus-e-x-e-y">E[XY] versus E[X]E[Y]</a></li>
<li class="toctree-l4"><a class="reference internal" href="#units-and-interpretation">Units and interpretation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="stat2_05.html">5. Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_06.html">6. Linear Functions and Sampling Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_07.html">7. Central Limit Theorem concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_08.html">8. Midterm review / assessment</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_09.html">9. Confidence intervals (Z-intervals)</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_10.html">10. t-distribution and confidence intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_11.html">11. Hypothesis testing logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_12.html">12. Type I / Type II errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_13.html">13. P-values and one-sample tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_14.html">14. Two-sample inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_15.html">15. Simple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat2_16.html">16. Regression adequacy and final assessment</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Statistics 2</a></li>
      <li class="breadcrumb-item active">4. Covariance</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/statistics2/stat2_04.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="covariance">
<h1>4. Covariance<a class="headerlink" href="#covariance" title="Link to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>In the previous reading on <strong>independence</strong>, we learned this key idea:</p>
<ul class="simple">
<li><p>If two random variables are <strong>independent</strong>, knowing one variable does <strong>not</strong> help you
predict the other one.</p></li>
<li><p>Independence is a strong statement about “no linkage” in probability.</p></li>
</ul>
<p>Now we learn <strong>covariance</strong>.</p>
<p>Covariance is a number that answers a different question:</p>
<ul class="simple">
<li><p>“When one variable is high, does the other variable also tend to be high?”</p></li>
<li><p>“When one variable is high, does the other variable tend to be low?”</p></li>
<li><p>“Or do they not move together in a clear straight-line way?”</p></li>
</ul>
<p>Covariance describes how two variables <strong>vary together</strong>.
“Vary” means “change.”
So covariance measures “together-change.”</p>
</section>
<section id="learning-outcomes">
<h2>Learning Outcomes<a class="headerlink" href="#learning-outcomes" title="Link to this heading"></a></h2>
<p>After this section, you should be able to:</p>
<ul class="simple">
<li><p>Explain covariance in plain words.</p></li>
<li><p>Compute covariance from a joint probability table.</p></li>
<li><p>Interpret the sign (positive, negative, or near zero).</p></li>
<li><p>Explain the connection between covariance and independence.</p></li>
</ul>
</section>
<section id="purpose-and-use-cases">
<h2>Purpose and Use Cases<a class="headerlink" href="#purpose-and-use-cases" title="Link to this heading"></a></h2>
<p>In many real processes, we measure two things at the same time.</p>
<p>Examples:</p>
<ul class="simple">
<li><p>A sensor’s signal strength and the system response time.</p></li>
<li><p>A machine’s vibration level and the surface roughness of parts.</p></li>
<li><p>Conveyor speed and the number of units that fail inspection.</p></li>
</ul>
<p>We want a tool that can summarize the relationship using <strong>one number</strong>.</p>
<p>Covariance gives that number.</p>
<p>Covariance does not try to describe every kind of relationship.
It mainly describes a <strong>linear</strong> (straight-line) together-pattern:</p>
<ul class="simple">
<li><p>One goes up, the other tends to go up  -&gt; positive covariance.</p></li>
<li><p>One goes up, the other tends to go down -&gt; negative covariance.</p></li>
<li><p>No clear straight-line direction -&gt; covariance near zero.</p></li>
</ul>
</section>
<section id="core-concept-and-notation">
<h2>Core Concept and Notation<a class="headerlink" href="#core-concept-and-notation" title="Link to this heading"></a></h2>
<section id="random-variables">
<h3>Random variables<a class="headerlink" href="#random-variables" title="Link to this heading"></a></h3>
<p>Let:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> be one random variable (random/unpredictable quantity).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Y</span></code> be another random variable.</p></li>
</ul>
<p>In a process setting, you can think of:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> as a measurement of a system condition (signal bars, temperature category, load level).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Y</span></code> as a measurement of performance (response time category, defect category, throughput category).</p></li>
</ul>
</section>
<section id="means-expected-values">
<h3>Means (expected values)<a class="headerlink" href="#means-expected-values" title="Link to this heading"></a></h3>
<p>We use:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_X = E[X]\)</span> is the mean (long-run average) of <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_Y = E[Y]\)</span> is the mean (long-run average) of <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
</ul>
<p>A mean is the “center” or “typical level.”</p>
</section>
<section id="deviations-from-the-mean">
<h3>Deviations from the mean<a class="headerlink" href="#deviations-from-the-mean" title="Link to this heading"></a></h3>
<p>We look at:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((X - \mu_X)\)</span> = how far <code class="docutils literal notranslate"><span class="pre">X</span></code> is above or below its mean.</p></li>
<li><p><span class="math notranslate nohighlight">\((Y - \mu_Y)\)</span> = how far <code class="docutils literal notranslate"><span class="pre">Y</span></code> is above or below its mean.</p></li>
</ul>
<p>These are called <strong>deviations</strong>.
Deviation means “difference from the average.”</p>
</section>
<section id="expected-value-of-a-function-of-two-variables">
<h3>Expected value of a function of two variables<a class="headerlink" href="#expected-value-of-a-function-of-two-variables" title="Link to this heading"></a></h3>
<p>Sometimes we need the expected value of a function that depends on both <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code>.
We write:</p>
<div class="math notranslate nohighlight">
\[E[h(X,Y)]\]</div>
<p>Interpretation:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">h(X,Y)</span></code> is a rule that takes a pair <code class="docutils literal notranslate"><span class="pre">(X,Y)</span></code> and produces one number.</p></li>
<li><p>The expectation is the long-run average of that output.</p></li>
</ul>
<p>If <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> are <strong>discrete</strong>:</p>
<div class="math notranslate nohighlight">
\[E[h(X,Y)] = \sum_x \sum_y h(x,y)\, f_{XY}(x,y)\]</div>
<p>If <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> are <strong>continuous</strong>:</p>
<div class="math notranslate nohighlight">
\[E[h(X,Y)] = \int \int h(x,y)\, f_{XY}(x,y)\, dx\, dy\]</div>
<p>In both cases, <span class="math notranslate nohighlight">\(f_{XY}(x,y)\)</span> is the <strong>joint distribution</strong>.
It tells us how likely each pair <code class="docutils literal notranslate"><span class="pre">(x,y)</span></code> is.</p>
</section>
</section>
<section id="definition-of-covariance">
<h2>Definition of Covariance<a class="headerlink" href="#definition-of-covariance" title="Link to this heading"></a></h2>
<p>Covariance is defined as:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = E\big[(X-\mu_X)(Y-\mu_Y)\big]\]</div>
<p>Read it slowly:</p>
<ol class="arabic simple">
<li><p>Find how far <code class="docutils literal notranslate"><span class="pre">X</span></code> is from its mean: <span class="math notranslate nohighlight">\(X-\mu_X\)</span>.</p></li>
<li><p>Find how far <code class="docutils literal notranslate"><span class="pre">Y</span></code> is from its mean: <span class="math notranslate nohighlight">\(Y-\mu_Y\)</span>.</p></li>
<li><p>Multiply them: <span class="math notranslate nohighlight">\((X-\mu_X)(Y-\mu_Y)\)</span>.</p></li>
<li><p>Take the expected value (the long-run average).</p></li>
</ol>
<section id="why-the-multiplication-works">
<h3>Why the multiplication works<a class="headerlink" href="#why-the-multiplication-works" title="Link to this heading"></a></h3>
<p>The product <span class="math notranslate nohighlight">\((X-\mu_X)(Y-\mu_Y)\)</span> carries direction information.</p>
<ul class="simple">
<li><p>If both are above their means, the product is positive.</p></li>
<li><p>If both are below their means, the product is also positive.</p></li>
<li><p>If one is above and the other is below, the product is negative.</p></li>
</ul>
<p>So covariance becomes an average “direction score”:</p>
<ul class="simple">
<li><p>Mostly positive products -&gt; positive covariance.</p></li>
<li><p>Mostly negative products -&gt; negative covariance.</p></li>
</ul>
</section>
<section id="a-convenient-formula">
<h3>A convenient formula<a class="headerlink" href="#a-convenient-formula" title="Link to this heading"></a></h3>
<p>Covariance can also be computed by:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = E[XY] - \mu_X \mu_Y\]</div>
<p>This form is often easier to compute.</p>
</section>
<section id="interpretation-of-the-sign">
<h3>Interpretation of the sign<a class="headerlink" href="#interpretation-of-the-sign" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Positive covariance</strong>:
When <code class="docutils literal notranslate"><span class="pre">X</span></code> is higher than usual, <code class="docutils literal notranslate"><span class="pre">Y</span></code> tends to be higher than usual.</p></li>
<li><p><strong>Negative covariance</strong>:
When <code class="docutils literal notranslate"><span class="pre">X</span></code> is higher than usual, <code class="docutils literal notranslate"><span class="pre">Y</span></code> tends to be lower than usual.</p></li>
<li><p><strong>Covariance near zero</strong>:
No clear straight-line together-pattern is visible.</p></li>
</ul>
<iframe src="../_static/04_01_Covariance_Sign.html"
        width="100%"
        height="420px"
        style="border:none;">
</iframe></section>
<section id="connection-to-independence">
<h3>Connection to independence<a class="headerlink" href="#connection-to-independence" title="Link to this heading"></a></h3>
<p>Independence is stronger than “zero covariance.”</p>
<p>Key fact:</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> are independent, then <span class="math notranslate nohighlight">\(\operatorname{cov}(X,Y)=0\)</span>.</p></li>
</ul>
<p>Reason:</p>
<ul class="simple">
<li><p>Independence implies <span class="math notranslate nohighlight">\(E[XY] = E[X]E[Y] = \mu_X\mu_Y\)</span>.</p></li>
<li><p>Then <span class="math notranslate nohighlight">\(E[XY] - \mu_X\mu_Y = 0\)</span>.</p></li>
</ul>
<p>Important warning:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\operatorname{cov}(X,Y)=0\)</span> does not always mean independence.</p></li>
<li><p>It only means the linear (straight-line) together-pattern is not strong.</p></li>
</ul>
<iframe src="../_static/04_02_Covariance_Contribution.html"
        width="100%"
        height="420px"
        style="border:none;">
</iframe></section>
</section>
<section id="worked-example">
<h2>Worked Example<a class="headerlink" href="#worked-example" title="Link to this heading"></a></h2>
<section id="scenario">
<h3>Scenario<a class="headerlink" href="#scenario" title="Link to this heading"></a></h3>
<p>A system records two discrete random variables for each task:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> = number of signal bars (1, 2, 3).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Y</span></code> = response time in seconds (1, 2, 3, 4).</p></li>
</ul>
<p>The joint probability table is:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Y=1</p></th>
<th class="head"><p>Y=2</p></th>
<th class="head"><p>Y=3</p></th>
<th class="head"><p>Y=4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>X=1</p></td>
<td><p>0.01</p></td>
<td><p>0.02</p></td>
<td><p>0.02</p></td>
<td><p>0.15</p></td>
</tr>
<tr class="row-odd"><td><p>X=2</p></td>
<td><p>0.02</p></td>
<td><p>0.03</p></td>
<td><p>0.10</p></td>
<td><p>0.10</p></td>
</tr>
<tr class="row-even"><td><p>X=3</p></td>
<td><p>0.25</p></td>
<td><p>0.20</p></td>
<td><p>0.05</p></td>
<td><p>0.05</p></td>
</tr>
</tbody>
</table>
<p>Goal: compute <span class="math notranslate nohighlight">\(\operatorname{cov}(X,Y)\)</span> and interpret it.</p>
</section>
<section id="step-1-find-the-marginal-distributions">
<h3>Step 1: Find the marginal distributions<a class="headerlink" href="#step-1-find-the-marginal-distributions" title="Link to this heading"></a></h3>
<p>Compute <span class="math notranslate nohighlight">\(f_X(x)\)</span> by summing each row:</p>
<div class="math notranslate nohighlight">
\[f_X(1)=0.01+0.02+0.02+0.15=0.20\]</div>
<div class="math notranslate nohighlight">
\[f_X(2)=0.02+0.03+0.10+0.10=0.25\]</div>
<div class="math notranslate nohighlight">
\[f_X(3)=0.25+0.20+0.05+0.05=0.55\]</div>
<p>Compute <span class="math notranslate nohighlight">\(f_Y(y)\)</span> by summing each column:</p>
<div class="math notranslate nohighlight">
\[f_Y(1)=0.01+0.02+0.25=0.28\]</div>
<div class="math notranslate nohighlight">
\[f_Y(2)=0.02+0.03+0.20=0.25\]</div>
<div class="math notranslate nohighlight">
\[f_Y(3)=0.02+0.10+0.05=0.17\]</div>
<div class="math notranslate nohighlight">
\[f_Y(4)=0.15+0.10+0.05=0.30\]</div>
</section>
<section id="step-2-compute-the-means-mu-x-and-mu-y">
<h3>Step 2: Compute the means mu_X and mu_Y<a class="headerlink" href="#step-2-compute-the-means-mu-x-and-mu-y" title="Link to this heading"></a></h3>
<p>Compute <span class="math notranslate nohighlight">\(\mu_X = E[X]\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mu_X = 1(0.20)+2(0.25)+3(0.55)
     = 0.20+0.50+1.65
     = 2.35\]</div>
<p>Compute <span class="math notranslate nohighlight">\(\mu_Y = E[Y]\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mu_Y = 1(0.28)+2(0.25)+3(0.17)+4(0.30)
     = 0.28+0.50+0.51+1.20
     = 2.49\]</div>
</section>
<section id="step-3-compute-e-xy-using-the-joint-distribution">
<h3>Step 3: Compute E[XY] using the joint distribution<a class="headerlink" href="#step-3-compute-e-xy-using-the-joint-distribution" title="Link to this heading"></a></h3>
<p>Use:</p>
<div class="math notranslate nohighlight">
\[E[XY] = \sum_x \sum_y (xy)\, f_{XY}(x,y)\]</div>
<p>Compute each weighted product:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((1\cdot 1)(0.01)=0.01\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((1\cdot 2)(0.02)=0.04\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((1\cdot 3)(0.02)=0.06\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((1\cdot 4)(0.15)=0.60\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((2\cdot 1)(0.02)=0.04\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((2\cdot 2)(0.03)=0.12\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((2\cdot 3)(0.10)=0.60\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((2\cdot 4)(0.10)=0.80\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((3\cdot 1)(0.25)=0.75\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((3\cdot 2)(0.20)=1.20\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((3\cdot 3)(0.05)=0.45\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((3\cdot 4)(0.05)=0.60\)</span></p></li>
</ul>
<p>Add them:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
   E[XY] &amp;= (0.01 + 0.04 + 0.06 + 0.60) \\
         &amp;\quad + (0.04 + 0.12 + 0.60 + 0.80) \\
         &amp;\quad + (0.75 + 1.20 + 0.45 + 0.60) \\
         &amp;= 5.27
\end{aligned}\end{split}\]</div>
<p>Before computing the final covariance, it is helpful to see how each outcome pair
adds a positive or negative contribution.</p>
<iframe src="../_static/04_03_Dependence_Heatmap.html"
        width="100%"
        height="420px"
        style="border:none;">
</iframe></section>
<section id="step-4-compute-covariance">
<h3>Step 4: Compute covariance<a class="headerlink" href="#step-4-compute-covariance" title="Link to this heading"></a></h3>
<p>Use:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = E[XY] - \mu_X\mu_Y\]</div>
<p>Substitute values:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = 5.27 - (2.35)(2.49)
                       = 5.27 - 5.8515
                       = -0.5815\]</div>
</section>
<section id="step-5-interpret-the-result">
<h3>Step 5: Interpret the result<a class="headerlink" href="#step-5-interpret-the-result" title="Link to this heading"></a></h3>
<p>The covariance is negative.</p>
<p>This means:</p>
<ul class="simple">
<li><p>When the signal bars are higher than usual, response time tends to be lower than usual.</p></li>
<li><p>When the signal bars are lower than usual, response time tends to be higher than usual.</p></li>
</ul>
<p>So signal strength and response time move in opposite directions.</p>
</section>
</section>
<section id="visual-intuition">
<h2>Visual Intuition<a class="headerlink" href="#visual-intuition" title="Link to this heading"></a></h2>
<section id="a-simple-point-cloud-picture">
<h3>A simple point-cloud picture<a class="headerlink" href="#a-simple-point-cloud-picture" title="Link to this heading"></a></h3>
<p>You can read covariance from a point cloud:</p>
<ul class="simple">
<li><p>An upward trend suggests positive covariance.</p></li>
<li><p>A downward trend suggests negative covariance.</p></li>
<li><p>No clear trend suggests covariance near zero.</p></li>
</ul>
<p>This idea is shown in Figure 04_02.</p>
</section>
<section id="the-above-below-average-picture">
<h3>The “above/below average” picture<a class="headerlink" href="#the-above-below-average-picture" title="Link to this heading"></a></h3>
<p>Covariance compares values to their means.</p>
<ul class="simple">
<li><p>Above-average <code class="docutils literal notranslate"><span class="pre">X</span></code> means <span class="math notranslate nohighlight">\(X &gt; \mu_X\)</span>.</p></li>
<li><p>Below-average <code class="docutils literal notranslate"><span class="pre">X</span></code> means <span class="math notranslate nohighlight">\(X &lt; \mu_X\)</span>.</p></li>
<li><p>Above-average <code class="docutils literal notranslate"><span class="pre">Y</span></code> means <span class="math notranslate nohighlight">\(Y &gt; \mu_Y\)</span>.</p></li>
<li><p>Below-average <code class="docutils literal notranslate"><span class="pre">Y</span></code> means <span class="math notranslate nohighlight">\(Y &lt; \mu_Y\)</span>.</p></li>
</ul>
<p>If above-average <code class="docutils literal notranslate"><span class="pre">X</span></code> tends to come with below-average <code class="docutils literal notranslate"><span class="pre">Y</span></code>, then covariance tends to be negative.
If above-average <code class="docutils literal notranslate"><span class="pre">X</span></code> tends to come with above-average <code class="docutils literal notranslate"><span class="pre">Y</span></code>, then covariance tends to be positive.</p>
</section>
</section>
<section id="discussion-and-common-errors">
<h2>Discussion and Common Errors<a class="headerlink" href="#discussion-and-common-errors" title="Link to this heading"></a></h2>
<section id="zero-covariance-and-independence">
<h3>Zero covariance and independence<a class="headerlink" href="#zero-covariance-and-independence" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> are independent, covariance is zero.</p></li>
<li><p>But covariance equal to zero does not always imply independence.
It only tells you there is no strong linear together-pattern.</p></li>
</ul>
<p>This is why it is useful to compare <span class="math notranslate nohighlight">\(f_{XY}(x,y)\)</span> with <span class="math notranslate nohighlight">\(f_X(x)f_Y(y)\)</span> as in Figure 04_04.</p>
</section>
<section id="e-xy-versus-e-x-e-y">
<h3>E[XY] versus E[X]E[Y]<a class="headerlink" href="#e-xy-versus-e-x-e-y" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E[XY]\)</span> uses the <strong>joint distribution</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(E[X]E[Y]\)</span> uses only the <strong>marginal distributions</strong>.</p></li>
</ul>
<p>These are equal when independence holds (or in special cases), but they are not equal in general.</p>
</section>
<section id="units-and-interpretation">
<h3>Units and interpretation<a class="headerlink" href="#units-and-interpretation" title="Link to this heading"></a></h3>
<p>Covariance depends on measurement scale.</p>
<p>Example idea:</p>
<ul class="simple">
<li><p>If you change response time from seconds to milliseconds, the covariance magnitude changes.</p></li>
<li><p>The sign still has the same meaning (same direction), but the number becomes larger.</p></li>
</ul>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<ul>
<li><p>Covariance measures how two random variables change together.</p></li>
<li><p>It is defined by:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = E[(X-\mu_X)(Y-\mu_Y)]\]</div>
</li>
<li><p>It can also be computed by:</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}(X,Y) = E[XY] - \mu_X\mu_Y\]</div>
</li>
<li><p>Positive covariance: both tend to move in the same direction.</p></li>
<li><p>Negative covariance: they tend to move in opposite directions.</p></li>
<li><p>Independence implies zero covariance, but zero covariance does not guarantee independence.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="stat2_03.html" class="btn btn-neutral float-left" title="3. Independence of Random Variables" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="stat2_05.html" class="btn btn-neutral float-right" title="5. Correlation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2026, Hendri Sutrisno.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>