

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. Sampling Distributions II: The Central Limit Theorem &mdash; Statistics</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=80f29991" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=fd6eb6e6"></script>
      <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Sampling Dist III: Chi-Square, t, and F" href="stat2_03_sampling_distributions_clt_and_normal_approx.html" />
    <link rel="prev" title="1. Sampling Distributions I: Random Sampling, Point Estimation, and Standard Error" href="stat2_01_random_sampling_point_est_std_error.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Courses</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../stat1/index.html">Statistics 1</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Statistics 2</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="stat2_01_random_sampling_point_est_std_error.html">1. Sampling Distributions I: Random Sampling, Point Estimation, and Standard Error</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2. Sampling Distributions II: The Central Limit Theorem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">2.1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-outcomes">2.2 Learning Outcomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#main-concepts">2.3 Main Concepts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sampling-distribution-of-the-sample-mean">2.3.1 Sampling Distribution of the Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="#exact-normal-case-a-special-baseline">2.3.2 Exact Normal Case (a special baseline)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#central-limit-theorem-approximate-normality">2.3.3 Central Limit Theorem (approximate Normality)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#standardization-and-the-z-statistic">2.3.4 Standardization and the Z Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="#when-does-the-clt-work-well-in-practice">2.3.5 When Does the CLT Work Well in Practice?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-2-1">2.3.6 Example 2.1</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-2-2">2.3.7 Example 2.2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#discussion-and-common-errors">2.4 Discussion and Common Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary">2.5 Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="stat2_03_sampling_distributions_clt_and_normal_approx.html">2. Sampling Dist III: Chi-Square, t, and F</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Statistics 2</a></li>
      <li class="breadcrumb-item active">2. Sampling Distributions II: The Central Limit Theorem</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/stat2/stat2_02_sampling_distributions_random_sampling.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sampling-distributions-ii-the-central-limit-theorem">
<h1>2. Sampling Distributions II: The Central Limit Theorem<a class="headerlink" href="#sampling-distributions-ii-the-central-limit-theorem" title="Link to this heading"></a></h1>
<table class="compact-notation docutils align-default" id="id1">
<caption><span class="caption-text">Notations used in this module</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 65.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Meaning</p></th>
<th class="head"><p>Notation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>One observation (measurement)</p></td>
<td><p><span class="math notranslate nohighlight">\(X\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Sample size (number of observations)</p></td>
<td><p><span class="math notranslate nohighlight">\(n\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Sample mean (average of the sample)</p></td>
<td><p><span class="math notranslate nohighlight">\(\bar{X}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Population mean (true long-run average)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Population standard deviation</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Standard error of the sample mean</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Standardized value (Z score)</p></td>
<td><p><span class="math notranslate nohighlight">\(Z=(\bar{X}-\mu)/(\sigma/\sqrt{n})\)</span></p></td>
</tr>
</tbody>
</table>
<section id="introduction">
<h2>2.1 Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>In Module 1, we introduced random sampling and the idea that statistics are random variables.
We used the standard error to describe the typical sampling-to-sampling variation of common statistics, especially the sample mean.
In this module, we move from “how variable is <span class="math notranslate nohighlight">\(\bar{X}\)</span>?” to “what is the shape of the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?”, because shape is what we need for probability calculations.</p>
<p>We use a convenience-store counter to motivate the setting.
A single counter may handle checkout plus additional services such as coffee orders, bill payment, document printing, meal heating, or kiosk confirmation.
Most transactions are short, but some are much longer, so completion time is often right-skewed.</p>
<p>One observation is one customer transaction.
Let <span class="math notranslate nohighlight">\(X\)</span> be the transaction completion time (minutes), defined by a fixed measurement rule:</p>
<ul class="simple">
<li><p>Start time: when the customer becomes the next person to be served at the counter</p></li>
<li><p>End time: when payment is confirmed and the customer leaves the counter</p></li>
</ul>
<p>This definition should be used consistently across shifts and observers.
If the measurement rule changes, then the recorded values do not represent the same variable, and comparisons across days become unreliable.</p>
</section>
<section id="learning-outcomes">
<h2>2.2 Learning Outcomes<a class="headerlink" href="#learning-outcomes" title="Link to this heading"></a></h2>
<p>After this session, we should be able to:</p>
<ul class="simple">
<li><p>Define the sampling distribution of the sample mean</p></li>
<li><p>State what the CLT guarantees, and what it does not guarantee</p></li>
<li><p>Use the standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> to quantify typical variation of <span class="math notranslate nohighlight">\(\bar{X}\)</span></p></li>
<li><p>Standardize the sample mean using a <span class="math notranslate nohighlight">\(Z\)</span>-statistic</p></li>
<li><p>Apply the CLT to approximate probabilities about averages</p></li>
<li><p>Explain when a Normal approximation is reasonable in applied work</p></li>
</ul>
</section>
<section id="main-concepts">
<h2>2.3 Main Concepts<a class="headerlink" href="#main-concepts" title="Link to this heading"></a></h2>
<section id="sampling-distribution-of-the-sample-mean">
<h3>2.3.1 Sampling Distribution of the Sample Mean<a class="headerlink" href="#sampling-distribution-of-the-sample-mean" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> be a random sample from a population with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.
The sample mean is the statistic</p>
<div class="math notranslate nohighlight">
\[\bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_i\]</div>
<p>The sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> describes how <span class="math notranslate nohighlight">\(\bar{X}\)</span> varies across repeated samples of the same size <span class="math notranslate nohighlight">\(n\)</span>.
Its center and spread follow two key results:</p>
<div class="math notranslate nohighlight">
\[E(\bar{X}) = \mu\]</div>
<div class="math notranslate nohighlight">
\[\mathrm{Var}(\bar{X}) = \frac{\sigma^2}{n}\]</div>
<p>Therefore, the standard deviation of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}\]</div>
<p>We call <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> the standard error of the sample mean.
It measures typical sampling-to-sampling variation of <span class="math notranslate nohighlight">\(\bar{X}\)</span> under repeated sampling.
As <span class="math notranslate nohighlight">\(n\)</span> increases, <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> decreases, so averages become more stable.</p>
<p>In the convenience-store case, a manager may monitor the average transaction time during a lunch period.
That reported average is one realized value of <span class="math notranslate nohighlight">\(\bar{X}\)</span>, based on a sample of transactions from that period.
The sampling distribution describes how that average would vary if we repeated the same sampling plan on many comparable days.</p>
</section>
<section id="exact-normal-case-a-special-baseline">
<h3>2.3.2 Exact Normal Case (a special baseline)<a class="headerlink" href="#exact-normal-case-a-special-baseline" title="Link to this heading"></a></h3>
<p>If the population distribution of <span class="math notranslate nohighlight">\(X\)</span> is Normal, then the sample mean is Normal for any sample size.
This result is exact:</p>
<div class="math notranslate nohighlight">
\[X \sim \mathcal{N}(\mu, \sigma^2)
\quad \Longrightarrow \quad
\bar{X} \sim \mathcal{N}\!\left(\mu, \frac{\sigma^2}{n}\right)\]</div>
<p>This baseline is important because it provides a clean reference case where Normal probability calculations for <span class="math notranslate nohighlight">\(\bar{X}\)</span> are always correct.
However, operational time variables (service times, transaction times, repair times) are often not Normal and are frequently right-skewed.
This motivates the need for an approximation result.</p>
</section>
<section id="central-limit-theorem-approximate-normality">
<h3>2.3.3 Central Limit Theorem (approximate Normality)<a class="headerlink" href="#central-limit-theorem-approximate-normality" title="Link to this heading"></a></h3>
<p>The Central Limit Theorem (CLT) explains why the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is often close to Normal even when the population is not Normal.
A practical version uses these assumptions:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> are independent</p></li>
<li><p>They share the same mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>They have finite variance <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
</ul>
<p>Under these conditions, the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> becomes approximately Normal as <span class="math notranslate nohighlight">\(n\)</span> increases.
The approximation has mean close to <span class="math notranslate nohighlight">\(\mu\)</span> and variance close to <span class="math notranslate nohighlight">\(\sigma^2/n\)</span>.
The word “approximately” is essential, because the accuracy depends on <span class="math notranslate nohighlight">\(n\)</span> and on how skewed or heavy-tailed the population is.</p>
<p>Figure 1 illustrates the CLT using simulated transaction completion times from a right-skewed population.
The population is generated to represent “many short transactions and a few long transactions,” which is common in service operations.
A repetition means drawing a new random sample of size <span class="math notranslate nohighlight">\(n\)</span> from this fixed population model and computing the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<p>The dropdown changes <span class="math notranslate nohighlight">\(n\)</span>, while the population mechanism is held fixed.
We compare the blue histogram (the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> across repetitions) to the gray Normal reference curve with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>.
As <span class="math notranslate nohighlight">\(n\)</span> increases, the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> becomes more symmetric and closer to the Normal reference.</p>
<p>Figure 1 illustrates this idea using simulated transaction-time data from a right-skewed population.
The data are simulated, but the mechanism is designed to represent “many short transactions and a few long transactions.”
A repetition means drawing a new random sample of <span class="math notranslate nohighlight">\(n\)</span> transactions from the same population and recomputing <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<p>The figure holds the population fixed and changes only the sample size <span class="math notranslate nohighlight">\(n\)</span>.
We compare the blue histogram (the simulated sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>) to the gray Normal reference curve with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>.
The main comparison is across values of <span class="math notranslate nohighlight">\(n\)</span>: as <span class="math notranslate nohighlight">\(n\)</span> increases, the histogram becomes more symmetric and aligns more closely with the Normal reference.</p>
<iframe src="../_static/figures/stat2/02_01_clt_xbar_convergence.html"
scrolling="no"
style="width:95%; height:560px; border:none; overflow:hidden; display:block; margin:0 auto;">
</iframe></section>
<section id="standardization-and-the-z-statistic">
<h3>2.3.4 Standardization and the Z Statistic<a class="headerlink" href="#standardization-and-the-z-statistic" title="Link to this heading"></a></h3>
<p>To use a Normal approximation consistently, we standardize the sample mean.
The standardized statistic is</p>
<div class="math notranslate nohighlight">
\[Z = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\]</div>
<p>The numerator <span class="math notranslate nohighlight">\(\bar{X}-\mu\)</span> is the deviation of the sample mean from the population mean.
The denominator <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> converts that deviation into standard-error units.
Under the CLT, <span class="math notranslate nohighlight">\(Z\)</span> is approximately <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span> when <span class="math notranslate nohighlight">\(n\)</span> is large enough for the approximation to be accurate.</p>
<p>Figure 2 shows this standardization using the same simulated right-skewed transaction-time process as Figure 1.
Each repetition produces a new sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>, which is then converted into a standardized value <span class="math notranslate nohighlight">\(Z\)</span>.
The dropdown changes <span class="math notranslate nohighlight">\(n\)</span>, and the x-axis range is fixed so that comparisons across <span class="math notranslate nohighlight">\(n\)</span> are fair.</p>
<p>We compare the blue histogram (the sampling distribution of <span class="math notranslate nohighlight">\(Z\)</span>) to the gray standard Normal reference curve.
For small <span class="math notranslate nohighlight">\(n\)</span>, the standardized distribution can still show skewness and tail differences.
For larger <span class="math notranslate nohighlight">\(n\)</span>, the histogram aligns more closely with <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span>, which supports the practical use of Normal probability calculations on the <span class="math notranslate nohighlight">\(Z\)</span> scale.</p>
<iframe src="../_static/figures/stat2/02_02_clt_standardized_z.html"
scrolling="no"
style="width:95%; height:560px; border:none; overflow:hidden; display:block; margin:0 auto;">
</iframe></section>
<section id="when-does-the-clt-work-well-in-practice">
<h3>2.3.5 When Does the CLT Work Well in Practice?<a class="headerlink" href="#when-does-the-clt-work-well-in-practice" title="Link to this heading"></a></h3>
<p>In practice, we use the CLT to approximate probabilities about averages.
A common guideline is that the approximation improves as <span class="math notranslate nohighlight">\(n\)</span> increases, and it improves faster when the population is not extremely skewed.
When <span class="math notranslate nohighlight">\(n\)</span> is small and the population is strongly right-skewed, tail probabilities can be noticeably inaccurate.</p>
<p>The sampling mechanism also matters.
The CLT assumes independence, but operational data can violate independence when system conditions persist over time.
In a convenience-store setting, transactions during a rush period can be similar because the queue, cashier, and service mix remain stable for several minutes.
This can increase the true sampling variability of <span class="math notranslate nohighlight">\(\bar{X}\)</span> beyond what <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> suggests.</p>
<p>Figure 3 focuses on tail-probability accuracy, because many operational decisions are threshold-based.
The data are simulated under two population types with the same <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>: one is strongly right-skewed (service-time-like) and one is Normal (a baseline where the Normal model is exact for <span class="math notranslate nohighlight">\(\bar{X}\)</span>).
A repetition means drawing a new sample of size <span class="math notranslate nohighlight">\(n\)</span>, computing <span class="math notranslate nohighlight">\(\bar{X}\)</span>, and checking whether a threshold event occurs.</p>
<p>For each <span class="math notranslate nohighlight">\(n\)</span>, we evaluate the event <span class="math notranslate nohighlight">\(\bar{X} &gt; \mu + 2(\sigma/\sqrt{n})\)</span>, which represents an “unusually high” average in standard-error units.
The orange trace reports the absolute difference between the simulated tail probability and the CLT-based approximation <span class="math notranslate nohighlight">\(P(Z&gt;2)\)</span>.
The gray baseline stays at zero because, when the population is Normal, the probability statement for <span class="math notranslate nohighlight">\(\bar{X}\)</span> is exactly the same as <span class="math notranslate nohighlight">\(P(Z&gt;2)\)</span> for every <span class="math notranslate nohighlight">\(n\)</span>.
The main comparison is how error changes with <span class="math notranslate nohighlight">\(n\)</span>: the overall trend decreases, even if small <span class="math notranslate nohighlight">\(n\)</span> values do not decrease perfectly monotonically.</p>
<iframe src="../_static/figures/stat2/02_03_clt_approximation_error.html"
scrolling="no"
style="width:95%; height:560px; border:none; overflow:hidden; display:block; margin:0 auto;">
</iframe></section>
<section id="example-2-1">
<h3>2.3.6 Example 2.1<a class="headerlink" href="#example-2-1" title="Link to this heading"></a></h3>
<p>A convenience store monitors transaction completion time <span class="math notranslate nohighlight">\(X\)</span> (minutes) during a stable period.
Historical monitoring suggests that <span class="math notranslate nohighlight">\(\mu = 1.24\)</span> minutes and <span class="math notranslate nohighlight">\(\sigma = 0.99\)</span> minutes for individual transactions.
A supervisor samples <span class="math notranslate nohighlight">\(n = 36\)</span> transactions from the lunch period and computes the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<p><strong>Question:</strong>
What is the approximate probability that the lunch-period average transaction time exceeds 1.50 minutes?</p>
<p>We want <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 1.50)\)</span>.
By the CLT, <span class="math notranslate nohighlight">\(\bar{X}\)</span> is approximately Normal with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>.
We first compute the standard error:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{0.99}{\sqrt{36}} = \frac{0.99}{6} = 0.165\]</div>
<p>We standardize the threshold 1.50:</p>
<div class="math notranslate nohighlight">
\[z = \frac{1.50 - 1.24}{0.165} \approx 1.58\]</div>
<p>Therefore,</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 1.50) \approx P(Z &gt; 1.58) \approx 0.057\]</div>
<p>This probability is about 5–6% under the Normal approximation.
In repeated lunch periods with the same stable process and the same sampling plan, an average above 1.50 minutes would be uncommon but not impossible.
If such events become frequent, it suggests a process change rather than random sampling variation.</p>
</section>
<section id="example-2-2">
<h3>2.3.7 Example 2.2<a class="headerlink" href="#example-2-2" title="Link to this heading"></a></h3>
<p>A manager wants to estimate the average transaction time during a rush period.
To save time, the manager samples <span class="math notranslate nohighlight">\(n = 30\)</span> consecutive customers from 12:00 to 12:10 and reports the sample mean.
This procedure is operationally convenient, but it can change the statistical properties of the sampling distribution.</p>
<p><strong>Question:</strong>
Why can consecutive sampling during a rush increase uncertainty in the sample mean?</p>
<p>During a rush, system conditions can persist.
For several minutes, the same cashier, queue length, and service mix can affect many consecutive customers in a similar way.
This creates dependence, meaning that transaction times can be positively correlated, and the effective information is smaller than <span class="math notranslate nohighlight">\(n\)</span> independent observations.
As a result, the true sampling variability of <span class="math notranslate nohighlight">\(\bar{X}\)</span> can be larger than <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>, and probability calculations based on independence can underestimate risk.</p>
</section>
</section>
<section id="discussion-and-common-errors">
<h2>2.4 Discussion and Common Errors<a class="headerlink" href="#discussion-and-common-errors" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Confusing the variability of <span class="math notranslate nohighlight">\(X\)</span> with the variability of <span class="math notranslate nohighlight">\(\bar{X}\)</span>.
Individual transaction times can be highly variable, especially under right-skewness.
The sample mean is less variable, and its typical variation is measured by <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>.</p></li>
<li><p>Applying the CLT without stating and checking the sampling mechanism.
Operational data can be dependent, especially when observations are collected consecutively in time during stable system conditions.
When dependence is present, <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> can be too small, and CLT-based probability calculations can be too optimistic.</p></li>
<li><p>Using a Normal approximation for extreme-tail decisions with small <span class="math notranslate nohighlight">\(n\)</span> under strong skewness.
Tail probabilities are often the last part of a distribution to be approximated well.
If tail accuracy is important, larger samples or simulation-based validation should be considered.</p></li>
</ol>
</section>
<section id="summary">
<h2>2.5 Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>The sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> describes how sample averages vary across repeated samples of size <span class="math notranslate nohighlight">\(n\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E(\bar{X})=\mu\)</span> and <span class="math notranslate nohighlight">\(\mathrm{Var}(\bar{X})=\sigma^2/n\)</span>, so the standard error is <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span></p></li>
<li><p>If the population is Normal, then <span class="math notranslate nohighlight">\(\bar{X}\)</span> is exactly Normal for any <span class="math notranslate nohighlight">\(n\)</span></p></li>
<li><p>The CLT implies that <span class="math notranslate nohighlight">\(\bar{X}\)</span> is approximately Normal for large <span class="math notranslate nohighlight">\(n\)</span> under independence and finite variance</p></li>
<li><p>Standardization via <span class="math notranslate nohighlight">\(Z=(\bar{X}-\mu)/(\sigma/\sqrt{n})\)</span> supports Normal probability calculations on a common scale</p></li>
<li><p>Skewness, dependence, and tail decisions can reduce approximation accuracy and require caution</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="stat2_01_random_sampling_point_est_std_error.html" class="btn btn-neutral float-left" title="1. Sampling Distributions I: Random Sampling, Point Estimation, and Standard Error" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="stat2_03_sampling_distributions_clt_and_normal_approx.html" class="btn btn-neutral float-right" title="2. Sampling Dist III: Chi-Square, t, and F" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2026, Hendri Sutrisno.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>